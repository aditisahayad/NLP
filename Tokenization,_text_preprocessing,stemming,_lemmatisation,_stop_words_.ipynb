{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGqn9WVJj4SF",
        "outputId": "a2ed0850-0dd1-4174-f3dc-8ceffbdaafc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "#punkt is a pretrained tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "ibiqEhXKkJYf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"Cricket, often referred to as the gentleman's game, is a bat-and-ball sport that has captured the hearts of millions around the world. Originating in England, cricket has evolved into a global phenomenon, uniting people across cultures and continents. This essay explores the history, rules, significance, and cultural impact of cricket, highlighting its role as a source of national pride and entertainment.\"\n",
        "\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TfCTxGNpkRG8",
        "outputId": "59877f48-a612-47e2-f305-26dbb46847c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Cricket, often referred to as the gentleman's game, is a bat-and-ball sport that has captured the hearts of millions around the world. Originating in England, cricket has evolved into a global phenomenon, uniting people across cultures and continents. This essay explores the history, rules, significance, and cultural impact of cricket, highlighting its role as a source of national pride and entertainment.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#From paragraph to sentence\n",
        "sentences = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "pg_op7zDkXxk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8CmjMPbkZ2T",
        "outputId": "c4723730-8385-4465-a8cb-ade903059e29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Cricket, often referred to as the gentleman's game, is a bat-and-ball sport that has captured the hearts of millions around the world.\",\n",
              " 'Originating in England, cricket has evolved into a global phenomenon, uniting people across cultures and continents.',\n",
              " 'This essay explores the history, rules, significance, and cultural impact of cricket, highlighting its role as a source of national pride and entertainment.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence to word\n",
        "from nltk.tokenize import word_tokenize #pretrained model\n",
        "\n",
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7APzlsbkdIt",
        "outputId": "ed06eb24-56da-4732-beb2-98412f324e55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cricket',\n",
              " ',',\n",
              " 'often',\n",
              " 'referred',\n",
              " 'to',\n",
              " 'as',\n",
              " 'the',\n",
              " 'gentleman',\n",
              " \"'s\",\n",
              " 'game',\n",
              " ',',\n",
              " 'is',\n",
              " 'a',\n",
              " 'bat-and-ball',\n",
              " 'sport',\n",
              " 'that',\n",
              " 'has',\n",
              " 'captured',\n",
              " 'the',\n",
              " 'hearts',\n",
              " 'of',\n",
              " 'millions',\n",
              " 'around',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'Originating',\n",
              " 'in',\n",
              " 'England',\n",
              " ',',\n",
              " 'cricket',\n",
              " 'has',\n",
              " 'evolved',\n",
              " 'into',\n",
              " 'a',\n",
              " 'global',\n",
              " 'phenomenon',\n",
              " ',',\n",
              " 'uniting',\n",
              " 'people',\n",
              " 'across',\n",
              " 'cultures',\n",
              " 'and',\n",
              " 'continents',\n",
              " '.',\n",
              " 'This',\n",
              " 'essay',\n",
              " 'explores',\n",
              " 'the',\n",
              " 'history',\n",
              " ',',\n",
              " 'rules',\n",
              " ',',\n",
              " 'significance',\n",
              " ',',\n",
              " 'and',\n",
              " 'cultural',\n",
              " 'impact',\n",
              " 'of',\n",
              " 'cricket',\n",
              " ',',\n",
              " 'highlighting',\n",
              " 'its',\n",
              " 'role',\n",
              " 'as',\n",
              " 'a',\n",
              " 'source',\n",
              " 'of',\n",
              " 'national',\n",
              " 'pride',\n",
              " 'and',\n",
              " 'entertainment',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize #regex based\n",
        "#it splits the words and punctuation separately\n",
        "\n",
        "wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_FwbsaWlC5N",
        "outputId": "867659a7-8b96-4172-b69d-5f54089d8f73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cricket',\n",
              " ',',\n",
              " 'often',\n",
              " 'referred',\n",
              " 'to',\n",
              " 'as',\n",
              " 'the',\n",
              " 'gentleman',\n",
              " \"'\",\n",
              " 's',\n",
              " 'game',\n",
              " ',',\n",
              " 'is',\n",
              " 'a',\n",
              " 'bat',\n",
              " '-',\n",
              " 'and',\n",
              " '-',\n",
              " 'ball',\n",
              " 'sport',\n",
              " 'that',\n",
              " 'has',\n",
              " 'captured',\n",
              " 'the',\n",
              " 'hearts',\n",
              " 'of',\n",
              " 'millions',\n",
              " 'around',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'Originating',\n",
              " 'in',\n",
              " 'England',\n",
              " ',',\n",
              " 'cricket',\n",
              " 'has',\n",
              " 'evolved',\n",
              " 'into',\n",
              " 'a',\n",
              " 'global',\n",
              " 'phenomenon',\n",
              " ',',\n",
              " 'uniting',\n",
              " 'people',\n",
              " 'across',\n",
              " 'cultures',\n",
              " 'and',\n",
              " 'continents',\n",
              " '.',\n",
              " 'This',\n",
              " 'essay',\n",
              " 'explores',\n",
              " 'the',\n",
              " 'history',\n",
              " ',',\n",
              " 'rules',\n",
              " ',',\n",
              " 'significance',\n",
              " ',',\n",
              " 'and',\n",
              " 'cultural',\n",
              " 'impact',\n",
              " 'of',\n",
              " 'cricket',\n",
              " ',',\n",
              " 'highlighting',\n",
              " 'its',\n",
              " 'role',\n",
              " 'as',\n",
              " 'a',\n",
              " 'source',\n",
              " 'of',\n",
              " 'national',\n",
              " 'pride',\n",
              " 'and',\n",
              " 'entertainment',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(\"is'nt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnQ0adxVlXKV",
        "outputId": "266b4044-13b6-43db-c9bf-f6366f72f493"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"is'nt\"]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(\"is'nt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X1qbcOHlrcH",
        "outputId": "2be8fdba-fa3b-45e8-b7a8-e0cf45d3cf54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is', \"'\", 'nt']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word_tokenize >> pretrained and dont consider punctuation (single quote, double quote)\n",
        "#wordpunct_tokenize >> regex based and consider punctuation"
      ],
      "metadata": {
        "id": "NNAIbKADltnz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordDetokenizer\n",
        "#rule based using the rules of Penn Treebank Corpus\n",
        "\n",
        "tokeniser = TreebankWordDetokenizer()\n",
        "tokeniser.tokenize(\"I can't beleive its already 1pm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WkOj8z3sl50t",
        "outputId": "4ad74cc2-bc50-40b5-d9af-3665905f7b28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I   c a n' t   b e l e i v e   i t s   a l r e a d y   1 p m\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using spacy\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "toM1wOB_m3ou"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Ram is a good boy\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMKCQ970nM6y",
        "outputId": "372b50c3-5adc-43df-cc63-0b1b63ce6ef4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ram is a good boy"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[token.text for token in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvl8-bK5nSr6",
        "outputId": "150018a4-d88e-4ab8-a743-9ba71f8f49e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ram', 'is', 'a', 'good', 'boy']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Preprocessing\n",
        "\n",
        "a = \"Shyam,\"\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yBNlzV-Ank6M",
        "outputId": "b54da7d1-3eaa-4be4-f900-cb245820af27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shyam,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we have to remove the ,\n",
        "#slicing\n",
        "a[:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3t8BEoP9od8c",
        "outputId": "274c1ccc-d404-4735-fe90-225dc1801fe2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shyam'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = \" beautiful\"\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "inyMSOIEoh5q",
        "outputId": "373879c7-7d99-4e73-b9b0-47a671e61de8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' beautiful'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the white space\n",
        "#split\n",
        "\n",
        "a.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGTx3_dhouyi",
        "outputId": "b5c26fd2-b6d7-4e50-8131-54597c170f3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['beautiful']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.upper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VtRF_8ozo01C",
        "outputId": "b0a7db6b-9bff-4bfc-b77d-ae55acf32004"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' BEAUTIFUL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0B-AdFz_o4Ji",
        "outputId": "4ac7569b-53d0-4bcc-d578-1b350ce3455f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' beautiful'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I have 10 chocolates\"\n",
        "\n",
        "# to remove the number either remove 10 or convert it into text\n",
        "\n",
        "#how to remove 10\n",
        "#using regex >> regular expression\n",
        "#It is a way to define a pattern for searching or manipulating strings\n",
        "# It is used to match, search,replace, and manipulate textual data\n",
        "\n",
        "#For example, Below are some of the cases where regular expression can help you to save a lot of time\n",
        "\n",
        "#searching and replacing text in files\n",
        "#Validating text input, such as password and email address\n",
        "#rename a 100 files at a time. For eg You can change the extension of all files using a regex pattern"
      ],
      "metadata": {
        "id": "iT90Z3-to71q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using re module\n",
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "xOhGSOlFtqfy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(re)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b6Nv0JztyZJ",
        "outputId": "e89bfb98-aef1-4e2d-ba47-1fd547a336b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package re:\n",
            "\n",
            "NAME\n",
            "    re - Support for regular expressions (RE).\n",
            "\n",
            "MODULE REFERENCE\n",
            "    https://docs.python.org/3.11/library/re.html\n",
            "    \n",
            "    The following documentation is automatically generated from the Python\n",
            "    source files.  It may be incomplete, incorrect or include features that\n",
            "    are considered implementation detail and may vary between Python\n",
            "    implementations.  When in doubt, consult the module reference at the\n",
            "    location listed above.\n",
            "\n",
            "DESCRIPTION\n",
            "    This module provides regular expression matching operations similar to\n",
            "    those found in Perl.  It supports both 8-bit and Unicode strings; both\n",
            "    the pattern and the strings being processed can contain null bytes and\n",
            "    characters outside the US ASCII range.\n",
            "    \n",
            "    Regular expressions can contain both special and ordinary characters.\n",
            "    Most ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\n",
            "    regular expressions; they simply match themselves.  You can\n",
            "    concatenate ordinary characters, so last matches the string 'last'.\n",
            "    \n",
            "    The special characters are:\n",
            "        \".\"      Matches any character except a newline.\n",
            "        \"^\"      Matches the start of the string.\n",
            "        \"$\"      Matches the end of the string or just before the newline at\n",
            "                 the end of the string.\n",
            "        \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n",
            "                 Greedy means that it will match as many repetitions as possible.\n",
            "        \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n",
            "        \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n",
            "        *?,+?,?? Non-greedy versions of the previous three special characters.\n",
            "        {m,n}    Matches from m to n repetitions of the preceding RE.\n",
            "        {m,n}?   Non-greedy version of the above.\n",
            "        \"\\\\\"     Either escapes special characters or signals a special sequence.\n",
            "        []       Indicates a set of characters.\n",
            "                 A \"^\" as the first character indicates a complementing set.\n",
            "        \"|\"      A|B, creates an RE that will match either A or B.\n",
            "        (...)    Matches the RE inside the parentheses.\n",
            "                 The contents can be retrieved or matched later in the string.\n",
            "        (?aiLmsux) The letters set the corresponding flags defined below.\n",
            "        (?:...)  Non-grouping version of regular parentheses.\n",
            "        (?P<name>...) The substring matched by the group is accessible by name.\n",
            "        (?P=name)     Matches the text matched earlier by the group named name.\n",
            "        (?#...)  A comment; ignored.\n",
            "        (?=...)  Matches if ... matches next, but doesn't consume the string.\n",
            "        (?!...)  Matches if ... doesn't match next.\n",
            "        (?<=...) Matches if preceded by ... (must be fixed length).\n",
            "        (?<!...) Matches if not preceded by ... (must be fixed length).\n",
            "        (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n",
            "                           the (optional) no pattern otherwise.\n",
            "    \n",
            "    The special sequences consist of \"\\\\\" and a character from the list\n",
            "    below.  If the ordinary character is not on the list, then the\n",
            "    resulting RE will match the second character.\n",
            "        \\number  Matches the contents of the group of the same number.\n",
            "        \\A       Matches only at the start of the string.\n",
            "        \\Z       Matches only at the end of the string.\n",
            "        \\b       Matches the empty string, but only at the start or end of a word.\n",
            "        \\B       Matches the empty string, but not at the start or end of a word.\n",
            "        \\d       Matches any decimal digit; equivalent to the set [0-9] in\n",
            "                 bytes patterns or string patterns with the ASCII flag.\n",
            "                 In string patterns without the ASCII flag, it will match the whole\n",
            "                 range of Unicode digits.\n",
            "        \\D       Matches any non-digit character; equivalent to [^\\d].\n",
            "        \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n",
            "                 bytes patterns or string patterns with the ASCII flag.\n",
            "                 In string patterns without the ASCII flag, it will match the whole\n",
            "                 range of Unicode whitespace characters.\n",
            "        \\S       Matches any non-whitespace character; equivalent to [^\\s].\n",
            "        \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n",
            "                 in bytes patterns or string patterns with the ASCII flag.\n",
            "                 In string patterns without the ASCII flag, it will match the\n",
            "                 range of Unicode alphanumeric characters (letters plus digits\n",
            "                 plus underscore).\n",
            "                 With LOCALE, it will match the set [0-9_] plus characters defined\n",
            "                 as letters for the current locale.\n",
            "        \\W       Matches the complement of \\w.\n",
            "        \\\\       Matches a literal backslash.\n",
            "    \n",
            "    This module exports the following functions:\n",
            "        match     Match a regular expression pattern to the beginning of a string.\n",
            "        fullmatch Match a regular expression pattern to all of a string.\n",
            "        search    Search a string for the presence of a pattern.\n",
            "        sub       Substitute occurrences of a pattern found in a string.\n",
            "        subn      Same as sub, but also return the number of substitutions made.\n",
            "        split     Split a string by the occurrences of a pattern.\n",
            "        findall   Find all occurrences of a pattern in a string.\n",
            "        finditer  Return an iterator yielding a Match object for each match.\n",
            "        compile   Compile a pattern into a Pattern object.\n",
            "        purge     Clear the regular expression cache.\n",
            "        escape    Backslash all non-alphanumerics in a string.\n",
            "    \n",
            "    Each function other than purge and escape can take an optional 'flags' argument\n",
            "    consisting of one or more of the following module constants, joined by \"|\".\n",
            "    A, L, and U are mutually exclusive.\n",
            "        A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n",
            "                       match the corresponding ASCII character categories\n",
            "                       (rather than the whole Unicode categories, which is the\n",
            "                       default).\n",
            "                       For bytes patterns, this flag is the only available\n",
            "                       behaviour and needn't be specified.\n",
            "        I  IGNORECASE  Perform case-insensitive matching.\n",
            "        L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n",
            "        M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n",
            "                       as well as the string.\n",
            "                       \"$\" matches the end of lines (before a newline) as well\n",
            "                       as the end of the string.\n",
            "        S  DOTALL      \".\" matches any character at all, including the newline.\n",
            "        X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n",
            "        U  UNICODE     For compatibility only. Ignored for string patterns (it\n",
            "                       is the default), and forbidden for bytes patterns.\n",
            "    \n",
            "    This module also defines an exception 'error'.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    _casefix\n",
            "    _compiler\n",
            "    _constants\n",
            "    _parser\n",
            "\n",
            "CLASSES\n",
            "    builtins.Exception(builtins.BaseException)\n",
            "        error\n",
            "    builtins.object\n",
            "        Match\n",
            "        Pattern\n",
            "    enum.IntFlag(builtins.int, enum.ReprEnum, enum.Flag)\n",
            "        RegexFlag\n",
            "    \n",
            "    class Match(builtins.object)\n",
            "     |  The result of re.match() and re.search().\n",
            "     |  Match objects always have a boolean value of True.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __copy__(self, /)\n",
            "     |  \n",
            "     |  __deepcopy__(self, memo, /)\n",
            "     |  \n",
            "     |  __getitem__(self, key, /)\n",
            "     |      Return self[key].\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  end(self, group=0, /)\n",
            "     |      Return index of the end of the substring matched by group.\n",
            "     |  \n",
            "     |  expand(self, /, template)\n",
            "     |      Return the string obtained by doing backslash substitution on the string template, as done by the sub() method.\n",
            "     |  \n",
            "     |  group(...)\n",
            "     |      group([group1, ...]) -> str or tuple.\n",
            "     |      Return subgroup(s) of the match by indices or names.\n",
            "     |      For 0 returns the entire match.\n",
            "     |  \n",
            "     |  groupdict(self, /, default=None)\n",
            "     |      Return a dictionary containing all the named subgroups of the match, keyed by the subgroup name.\n",
            "     |      \n",
            "     |      default\n",
            "     |        Is used for groups that did not participate in the match.\n",
            "     |  \n",
            "     |  groups(self, /, default=None)\n",
            "     |      Return a tuple containing all the subgroups of the match, from 1.\n",
            "     |      \n",
            "     |      default\n",
            "     |        Is used for groups that did not participate in the match.\n",
            "     |  \n",
            "     |  span(self, group=0, /)\n",
            "     |      For match object m, return the 2-tuple (m.start(group), m.end(group)).\n",
            "     |  \n",
            "     |  start(self, group=0, /)\n",
            "     |      Return index of the start of the substring matched by group.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods defined here:\n",
            "     |  \n",
            "     |  __class_getitem__(...)\n",
            "     |      See PEP 585\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  endpos\n",
            "     |      The index into the string beyond which the RE engine will not go.\n",
            "     |  \n",
            "     |  lastgroup\n",
            "     |      The name of the last matched capturing group.\n",
            "     |  \n",
            "     |  lastindex\n",
            "     |      The integer index of the last matched capturing group.\n",
            "     |  \n",
            "     |  pos\n",
            "     |      The index into the string at which the RE engine started looking for a match.\n",
            "     |  \n",
            "     |  re\n",
            "     |      The regular expression object.\n",
            "     |  \n",
            "     |  regs\n",
            "     |  \n",
            "     |  string\n",
            "     |      The string passed to match() or search().\n",
            "    \n",
            "    class Pattern(builtins.object)\n",
            "     |  Compiled regular expression object.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __copy__(self, /)\n",
            "     |  \n",
            "     |  __deepcopy__(self, memo, /)\n",
            "     |  \n",
            "     |  __eq__(self, value, /)\n",
            "     |      Return self==value.\n",
            "     |  \n",
            "     |  __ge__(self, value, /)\n",
            "     |      Return self>=value.\n",
            "     |  \n",
            "     |  __gt__(self, value, /)\n",
            "     |      Return self>value.\n",
            "     |  \n",
            "     |  __hash__(self, /)\n",
            "     |      Return hash(self).\n",
            "     |  \n",
            "     |  __le__(self, value, /)\n",
            "     |      Return self<=value.\n",
            "     |  \n",
            "     |  __lt__(self, value, /)\n",
            "     |      Return self<value.\n",
            "     |  \n",
            "     |  __ne__(self, value, /)\n",
            "     |      Return self!=value.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  findall(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Return a list of all non-overlapping matches of pattern in string.\n",
            "     |  \n",
            "     |  finditer(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Return an iterator over all non-overlapping matches for the RE pattern in string.\n",
            "     |      \n",
            "     |      For each match, the iterator returns a match object.\n",
            "     |  \n",
            "     |  fullmatch(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Matches against all of the string.\n",
            "     |  \n",
            "     |  match(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Matches zero or more characters at the beginning of the string.\n",
            "     |  \n",
            "     |  scanner(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |  \n",
            "     |  search(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Scan through string looking for a match, and return a corresponding match object instance.\n",
            "     |      \n",
            "     |      Return None if no position in the string matches.\n",
            "     |  \n",
            "     |  split(self, /, string, maxsplit=0)\n",
            "     |      Split string by the occurrences of pattern.\n",
            "     |  \n",
            "     |  sub(self, /, repl, string, count=0)\n",
            "     |      Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl.\n",
            "     |  \n",
            "     |  subn(self, /, repl, string, count=0)\n",
            "     |      Return the tuple (new_string, number_of_subs_made) found by replacing the leftmost non-overlapping occurrences of pattern with the replacement repl.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods defined here:\n",
            "     |  \n",
            "     |  __class_getitem__(...)\n",
            "     |      See PEP 585\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  flags\n",
            "     |      The regex matching flags.\n",
            "     |  \n",
            "     |  groupindex\n",
            "     |      A dictionary mapping group names to group numbers.\n",
            "     |  \n",
            "     |  groups\n",
            "     |      The number of capturing groups in the pattern.\n",
            "     |  \n",
            "     |  pattern\n",
            "     |      The pattern string from which the RE object was compiled.\n",
            "    \n",
            "    class RegexFlag(enum.IntFlag)\n",
            "     |  RegexFlag(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
            "     |  \n",
            "     |  An enumeration.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      RegexFlag\n",
            "     |      enum.IntFlag\n",
            "     |      builtins.int\n",
            "     |      enum.ReprEnum\n",
            "     |      enum.Flag\n",
            "     |      enum.Enum\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __and__(self, other) from enum.Flag\n",
            "     |  \n",
            "     |  __format__(self, format_spec, /) from builtins.int\n",
            "     |      Default object formatter.\n",
            "     |  \n",
            "     |  __invert__(self) from enum.Flag\n",
            "     |  \n",
            "     |  __new__(cls, value) from enum.Enum\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  __or__(self, other) from enum.Flag\n",
            "     |      Return self|value.\n",
            "     |  \n",
            "     |  __rand__ = __and__(self, other)\n",
            "     |  \n",
            "     |  __repr__ = global_flag_repr(self) from enum\n",
            "     |      use module.flag_name instead of class.flag_name\n",
            "     |      \n",
            "     |      the module is the last module in case of a multi-module name\n",
            "     |  \n",
            "     |  __ror__ = __or__(self, other)\n",
            "     |  \n",
            "     |  __rxor__ = __xor__(self, other)\n",
            "     |  \n",
            "     |  __str__(self, /) from builtins.object\n",
            "     |      Return str(self).\n",
            "     |  \n",
            "     |  __xor__(self, other) from enum.Flag\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  ASCII = re.ASCII\n",
            "     |  \n",
            "     |  DEBUG = re.DEBUG\n",
            "     |  \n",
            "     |  DOTALL = re.DOTALL\n",
            "     |  \n",
            "     |  IGNORECASE = re.IGNORECASE\n",
            "     |  \n",
            "     |  LOCALE = re.LOCALE\n",
            "     |  \n",
            "     |  MULTILINE = re.MULTILINE\n",
            "     |  \n",
            "     |  TEMPLATE = re.TEMPLATE\n",
            "     |  \n",
            "     |  UNICODE = re.UNICODE\n",
            "     |  \n",
            "     |  VERBOSE = re.VERBOSE\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.int:\n",
            "     |  \n",
            "     |  __abs__(self, /)\n",
            "     |      abs(self)\n",
            "     |  \n",
            "     |  __add__(self, value, /)\n",
            "     |      Return self+value.\n",
            "     |  \n",
            "     |  __bool__(self, /)\n",
            "     |      True if self else False\n",
            "     |  \n",
            "     |  __ceil__(...)\n",
            "     |      Ceiling of an Integral returns itself.\n",
            "     |  \n",
            "     |  __divmod__(self, value, /)\n",
            "     |      Return divmod(self, value).\n",
            "     |  \n",
            "     |  __eq__(self, value, /)\n",
            "     |      Return self==value.\n",
            "     |  \n",
            "     |  __float__(self, /)\n",
            "     |      float(self)\n",
            "     |  \n",
            "     |  __floor__(...)\n",
            "     |      Flooring an Integral returns itself.\n",
            "     |  \n",
            "     |  __floordiv__(self, value, /)\n",
            "     |      Return self//value.\n",
            "     |  \n",
            "     |  __ge__(self, value, /)\n",
            "     |      Return self>=value.\n",
            "     |  \n",
            "     |  __getattribute__(self, name, /)\n",
            "     |      Return getattr(self, name).\n",
            "     |  \n",
            "     |  __getnewargs__(self, /)\n",
            "     |  \n",
            "     |  __gt__(self, value, /)\n",
            "     |      Return self>value.\n",
            "     |  \n",
            "     |  __hash__(self, /)\n",
            "     |      Return hash(self).\n",
            "     |  \n",
            "     |  __index__(self, /)\n",
            "     |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
            "     |  \n",
            "     |  __int__(self, /)\n",
            "     |      int(self)\n",
            "     |  \n",
            "     |  __le__(self, value, /)\n",
            "     |      Return self<=value.\n",
            "     |  \n",
            "     |  __lshift__(self, value, /)\n",
            "     |      Return self<<value.\n",
            "     |  \n",
            "     |  __lt__(self, value, /)\n",
            "     |      Return self<value.\n",
            "     |  \n",
            "     |  __mod__(self, value, /)\n",
            "     |      Return self%value.\n",
            "     |  \n",
            "     |  __mul__(self, value, /)\n",
            "     |      Return self*value.\n",
            "     |  \n",
            "     |  __ne__(self, value, /)\n",
            "     |      Return self!=value.\n",
            "     |  \n",
            "     |  __neg__(self, /)\n",
            "     |      -self\n",
            "     |  \n",
            "     |  __pos__(self, /)\n",
            "     |      +self\n",
            "     |  \n",
            "     |  __pow__(self, value, mod=None, /)\n",
            "     |      Return pow(self, value, mod).\n",
            "     |  \n",
            "     |  __radd__(self, value, /)\n",
            "     |      Return value+self.\n",
            "     |  \n",
            "     |  __rdivmod__(self, value, /)\n",
            "     |      Return divmod(value, self).\n",
            "     |  \n",
            "     |  __rfloordiv__(self, value, /)\n",
            "     |      Return value//self.\n",
            "     |  \n",
            "     |  __rlshift__(self, value, /)\n",
            "     |      Return value<<self.\n",
            "     |  \n",
            "     |  __rmod__(self, value, /)\n",
            "     |      Return value%self.\n",
            "     |  \n",
            "     |  __rmul__(self, value, /)\n",
            "     |      Return value*self.\n",
            "     |  \n",
            "     |  __round__(...)\n",
            "     |      Rounding an Integral returns itself.\n",
            "     |      \n",
            "     |      Rounding with an ndigits argument also returns an integer.\n",
            "     |  \n",
            "     |  __rpow__(self, value, mod=None, /)\n",
            "     |      Return pow(value, self, mod).\n",
            "     |  \n",
            "     |  __rrshift__(self, value, /)\n",
            "     |      Return value>>self.\n",
            "     |  \n",
            "     |  __rshift__(self, value, /)\n",
            "     |      Return self>>value.\n",
            "     |  \n",
            "     |  __rsub__(self, value, /)\n",
            "     |      Return value-self.\n",
            "     |  \n",
            "     |  __rtruediv__(self, value, /)\n",
            "     |      Return value/self.\n",
            "     |  \n",
            "     |  __sizeof__(self, /)\n",
            "     |      Returns size in memory, in bytes.\n",
            "     |  \n",
            "     |  __sub__(self, value, /)\n",
            "     |      Return self-value.\n",
            "     |  \n",
            "     |  __truediv__(self, value, /)\n",
            "     |      Return self/value.\n",
            "     |  \n",
            "     |  __trunc__(...)\n",
            "     |      Truncating an Integral returns itself.\n",
            "     |  \n",
            "     |  as_integer_ratio(self, /)\n",
            "     |      Return integer ratio.\n",
            "     |      \n",
            "     |      Return a pair of integers, whose ratio is exactly equal to the original int\n",
            "     |      and with a positive denominator.\n",
            "     |      \n",
            "     |      >>> (10).as_integer_ratio()\n",
            "     |      (10, 1)\n",
            "     |      >>> (-10).as_integer_ratio()\n",
            "     |      (-10, 1)\n",
            "     |      >>> (0).as_integer_ratio()\n",
            "     |      (0, 1)\n",
            "     |  \n",
            "     |  bit_count(self, /)\n",
            "     |      Number of ones in the binary representation of the absolute value of self.\n",
            "     |      \n",
            "     |      Also known as the population count.\n",
            "     |      \n",
            "     |      >>> bin(13)\n",
            "     |      '0b1101'\n",
            "     |      >>> (13).bit_count()\n",
            "     |      3\n",
            "     |  \n",
            "     |  bit_length(self, /)\n",
            "     |      Number of bits necessary to represent self in binary.\n",
            "     |      \n",
            "     |      >>> bin(37)\n",
            "     |      '0b100101'\n",
            "     |      >>> (37).bit_length()\n",
            "     |      6\n",
            "     |  \n",
            "     |  conjugate(...)\n",
            "     |      Returns self, the complex conjugate of any int.\n",
            "     |  \n",
            "     |  to_bytes(self, /, length=1, byteorder='big', *, signed=False)\n",
            "     |      Return an array of bytes representing an integer.\n",
            "     |      \n",
            "     |      length\n",
            "     |        Length of bytes object to use.  An OverflowError is raised if the\n",
            "     |        integer is not representable with the given number of bytes.  Default\n",
            "     |        is length 1.\n",
            "     |      byteorder\n",
            "     |        The byte order used to represent the integer.  If byteorder is 'big',\n",
            "     |        the most significant byte is at the beginning of the byte array.  If\n",
            "     |        byteorder is 'little', the most significant byte is at the end of the\n",
            "     |        byte array.  To request the native byte order of the host system, use\n",
            "     |        `sys.byteorder' as the byte order value.  Default is to use 'big'.\n",
            "     |      signed\n",
            "     |        Determines whether two's complement is used to represent the integer.\n",
            "     |        If signed is False and a negative integer is given, an OverflowError\n",
            "     |        is raised.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods inherited from builtins.int:\n",
            "     |  \n",
            "     |  from_bytes(bytes, byteorder='big', *, signed=False)\n",
            "     |      Return the integer represented by the given array of bytes.\n",
            "     |      \n",
            "     |      bytes\n",
            "     |        Holds the array of bytes to convert.  The argument must either\n",
            "     |        support the buffer protocol or be an iterable object producing bytes.\n",
            "     |        Bytes and bytearray are examples of built-in objects that support the\n",
            "     |        buffer protocol.\n",
            "     |      byteorder\n",
            "     |        The byte order used to represent the integer.  If byteorder is 'big',\n",
            "     |        the most significant byte is at the beginning of the byte array.  If\n",
            "     |        byteorder is 'little', the most significant byte is at the end of the\n",
            "     |        byte array.  To request the native byte order of the host system, use\n",
            "     |        `sys.byteorder' as the byte order value.  Default is to use 'big'.\n",
            "     |      signed\n",
            "     |        Indicates whether two's complement is used to represent the integer.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from builtins.int:\n",
            "     |  \n",
            "     |  denominator\n",
            "     |      the denominator of a rational number in lowest terms\n",
            "     |  \n",
            "     |  imag\n",
            "     |      the imaginary part of a complex number\n",
            "     |  \n",
            "     |  numerator\n",
            "     |      the numerator of a rational number in lowest terms\n",
            "     |  \n",
            "     |  real\n",
            "     |      the real part of a complex number\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from enum.Flag:\n",
            "     |  \n",
            "     |  __contains__(self, other)\n",
            "     |      Returns True if self has at least the same flags set as other.\n",
            "     |  \n",
            "     |  __iter__(self)\n",
            "     |      Returns flags in definition order.\n",
            "     |  \n",
            "     |  __len__(self)\n",
            "     |      Return the number of members (no aliases)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from enum.Enum:\n",
            "     |  \n",
            "     |  __dir__(self)\n",
            "     |      Returns public methods and other interesting attributes.\n",
            "     |  \n",
            "     |  __init__(self, *args, **kwds)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __reduce_ex__(self, proto)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from enum.Enum:\n",
            "     |  \n",
            "     |  name\n",
            "     |      The name of the Enum member.\n",
            "     |  \n",
            "     |  value\n",
            "     |      The value of the Enum member.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from enum.EnumType:\n",
            "     |  \n",
            "     |  __getitem__(name)\n",
            "     |      Return the member matching `name`.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties inherited from enum.EnumType:\n",
            "     |  \n",
            "     |  __members__\n",
            "     |      Returns a mapping of member name->value.\n",
            "     |      \n",
            "     |      This mapping lists all enum members, including aliases. Note that this\n",
            "     |      is a read-only view of the internal mapping.\n",
            "    \n",
            "    class error(builtins.Exception)\n",
            "     |  error(msg, pattern=None, pos=None)\n",
            "     |  \n",
            "     |  Exception raised for invalid regular expressions.\n",
            "     |  \n",
            "     |  Attributes:\n",
            "     |  \n",
            "     |      msg: The unformatted error message\n",
            "     |      pattern: The regular expression pattern\n",
            "     |      pos: The index in the pattern where compilation failed (may be None)\n",
            "     |      lineno: The line corresponding to pos (may be None)\n",
            "     |      colno: The column corresponding to pos (may be None)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      error\n",
            "     |      builtins.Exception\n",
            "     |      builtins.BaseException\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, msg, pattern=None, pos=None) from re._constants.error\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from builtins.Exception:\n",
            "     |  \n",
            "     |  __new__(*args, **kwargs) class method of builtins.Exception\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __delattr__(self, name, /)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getattribute__(self, name, /)\n",
            "     |      Return getattr(self, name).\n",
            "     |  \n",
            "     |  __reduce__(...)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setattr__(self, name, value, /)\n",
            "     |      Implement setattr(self, name, value).\n",
            "     |  \n",
            "     |  __setstate__(...)\n",
            "     |  \n",
            "     |  __str__(self, /)\n",
            "     |      Return str(self).\n",
            "     |  \n",
            "     |  add_note(...)\n",
            "     |      Exception.add_note(note) --\n",
            "     |      add a note to the exception\n",
            "     |  \n",
            "     |  with_traceback(...)\n",
            "     |      Exception.with_traceback(tb) --\n",
            "     |      set self.__traceback__ to tb and return self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __cause__\n",
            "     |      exception cause\n",
            "     |  \n",
            "     |  __context__\n",
            "     |      exception context\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |  \n",
            "     |  __suppress_context__\n",
            "     |  \n",
            "     |  __traceback__\n",
            "     |  \n",
            "     |  args\n",
            "\n",
            "FUNCTIONS\n",
            "    compile(pattern, flags=0)\n",
            "        Compile a regular expression pattern, returning a Pattern object.\n",
            "    \n",
            "    escape(pattern)\n",
            "        Escape special characters in a string.\n",
            "    \n",
            "    findall(pattern, string, flags=0)\n",
            "        Return a list of all non-overlapping matches in the string.\n",
            "        \n",
            "        If one or more capturing groups are present in the pattern, return\n",
            "        a list of groups; this will be a list of tuples if the pattern\n",
            "        has more than one group.\n",
            "        \n",
            "        Empty matches are included in the result.\n",
            "    \n",
            "    finditer(pattern, string, flags=0)\n",
            "        Return an iterator over all non-overlapping matches in the\n",
            "        string.  For each match, the iterator returns a Match object.\n",
            "        \n",
            "        Empty matches are included in the result.\n",
            "    \n",
            "    fullmatch(pattern, string, flags=0)\n",
            "        Try to apply the pattern to all of the string, returning\n",
            "        a Match object, or None if no match was found.\n",
            "    \n",
            "    match(pattern, string, flags=0)\n",
            "        Try to apply the pattern at the start of the string, returning\n",
            "        a Match object, or None if no match was found.\n",
            "    \n",
            "    purge()\n",
            "        Clear the regular expression caches\n",
            "    \n",
            "    search(pattern, string, flags=0)\n",
            "        Scan through string looking for a match to the pattern, returning\n",
            "        a Match object, or None if no match was found.\n",
            "    \n",
            "    split(pattern, string, maxsplit=0, flags=0)\n",
            "        Split the source string by the occurrences of the pattern,\n",
            "        returning a list containing the resulting substrings.  If\n",
            "        capturing parentheses are used in pattern, then the text of all\n",
            "        groups in the pattern are also returned as part of the resulting\n",
            "        list.  If maxsplit is nonzero, at most maxsplit splits occur,\n",
            "        and the remainder of the string is returned as the final element\n",
            "        of the list.\n",
            "    \n",
            "    sub(pattern, repl, string, count=0, flags=0)\n",
            "        Return the string obtained by replacing the leftmost\n",
            "        non-overlapping occurrences of the pattern in string by the\n",
            "        replacement repl.  repl can be either a string or a callable;\n",
            "        if a string, backslash escapes in it are processed.  If it is\n",
            "        a callable, it's passed the Match object and must return\n",
            "        a replacement string to be used.\n",
            "    \n",
            "    subn(pattern, repl, string, count=0, flags=0)\n",
            "        Return a 2-tuple containing (new_string, number).\n",
            "        new_string is the string obtained by replacing the leftmost\n",
            "        non-overlapping occurrences of the pattern in the source\n",
            "        string by the replacement repl.  number is the number of\n",
            "        substitutions that were made. repl can be either a string or a\n",
            "        callable; if a string, backslash escapes in it are processed.\n",
            "        If it is a callable, it's passed the Match object and must\n",
            "        return a replacement string to be used.\n",
            "    \n",
            "    template(pattern, flags=0)\n",
            "        Compile a template pattern, returning a Pattern object, deprecated\n",
            "\n",
            "DATA\n",
            "    A = re.ASCII\n",
            "    ASCII = re.ASCII\n",
            "    DOTALL = re.DOTALL\n",
            "    I = re.IGNORECASE\n",
            "    IGNORECASE = re.IGNORECASE\n",
            "    L = re.LOCALE\n",
            "    LOCALE = re.LOCALE\n",
            "    M = re.MULTILINE\n",
            "    MULTILINE = re.MULTILINE\n",
            "    NOFLAG = re.NOFLAG\n",
            "    S = re.DOTALL\n",
            "    U = re.UNICODE\n",
            "    UNICODE = re.UNICODE\n",
            "    VERBOSE = re.VERBOSE\n",
            "    X = re.VERBOSE\n",
            "    __all__ = ['match', 'fullmatch', 'search', 'sub', 'subn', 'split', 'fi...\n",
            "\n",
            "VERSION\n",
            "    2.2.1\n",
            "\n",
            "FILE\n",
            "    /usr/lib/python3.11/re/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write a regular expression to search/find all the digits inside the strings\n",
        "\n",
        "data = \"I have 10 chocolates and 1 bat\"\n",
        "re.findall(r\"\\d\",data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXNSsA1xt0D4",
        "outputId": "09d6b981-f40c-41f7-8edd-97e03c6bc1ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '0', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r\"\\d+\",data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YZYH9QjuRxK",
        "outputId": "82765b11-4238-495e-8340-fe4c636bd264"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r\"\\d*\",data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYiofV39vJIC",
        "outputId": "1b9d4e70-f2e2-4fff-bb77-1ea25f20bfc2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '10',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '1',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The OTP is 12310\"\n",
        "re.findall(r\"\\d*\",sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOCJGna-vXi5",
        "outputId": "63d93f0c-6f8d-4d39-fad6-21df8e5193f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '', '', '', '', '', '', '', '', '', '12310', '']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"My salary is $200\"\n",
        "re.findall(r\"\\$\\d*\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGOjaRN_w9YI",
        "outputId": "276f3308-28da-4c5f-920c-c7449f1329df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$200']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"My salary is ^200\"\n",
        "re.findall(r\"\\^\\d*\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV-aMurqxK5T",
        "outputId": "747bd705-38a3-4dac-db0f-dad19a6f4b24"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['^200']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"My salary is &200\"\n",
        "re.findall(r\"\\&\\d*\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4vLOF_8xUVy",
        "outputId": "c692b67f-da64-4236-9324-90ce0bc9e10d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['&200']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"My salary is $200.42\"\n",
        "re.findall(r\"\\$\\d*\\.\\d+\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIRHMQ_Oxdg5",
        "outputId": "685961da-de58-4411-f93a-f520e8daf085"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$200.42']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"My payment of $200.42 and $300.4245 is successfull\"\n",
        "re.findall(r\"\\$\\d*\\.\\d+\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKRRmhIkxp9N",
        "outputId": "8b1d16e7-b2da-43fe-82eb-d4668945f555"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$200.42', '$300.4245']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"My payment of $200.42 and &300.4 is successfull\"\n",
        "re.findall(r\"[\\$&]\\d+(?:\\.\\d+)\", s) #(?:\\.\\d+) this will match decimal part"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUIqsSWhyZBI",
        "outputId": "01a8c9c4-bf36-45d4-bd4c-30d2ce9cb1d6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$200.42', '&300.4']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove the number\n",
        "\n",
        "data = \"I have 10 chocolates\"\n",
        "re.sub(r\"\\d\",\"\",data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "52VJYh2vzWoM",
        "outputId": "2e8fb41a-27a8-4635-e086-fb2054d6a99f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have  chocolates'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove the number\n",
        "\n",
        "data = \"I have 10 chocolates and 6 bat\"\n",
        "re.sub(r\"\\d+\",\"\",data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nzsPgfMK0iao",
        "outputId": "978fed45-0168-4d92-ee26-4841f64188dc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have  chocolates and  bat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inflect\n",
        "q = inflect.engine()"
      ],
      "metadata": {
        "id": "DgGgroAN1I1h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q.number_to_words(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2CM-z6nt1QHX",
        "outputId": "7cdcf298-28c6-4cfd-e837-c74f814585c4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ten'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inflect\n",
        "\n",
        "# Create an engine for inflect\n",
        "p = inflect.engine()\n",
        "\n",
        "# Convert number into text\n",
        "def convert_num(text):\n",
        "    # Split string into list of words\n",
        "    temp_string = text.split()\n",
        "    # Initialise empty list\n",
        "    new_str = []\n",
        "\n",
        "    for word in temp_string:\n",
        "        # If the word is a digit, convert it to words\n",
        "        if word.isdigit():\n",
        "            temp = p.number_to_words(word)\n",
        "            new_str.append(temp)\n",
        "        else:\n",
        "            new_str.append(word)\n",
        "\n",
        "    # Join the new_str list back into a string\n",
        "    temp_str = ' '.join(new_str)\n",
        "    return temp_str\n",
        "\n",
        "# Example usage\n",
        "input_str = \"You have 6 chocolate and 4 candies\"\n",
        "output = convert_num(input_str)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUa6_3JY0p1s",
        "outputId": "7b748af1-ddc7-48e0-c930-a4b193b968c8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have six chocolate and four candies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_str\n",
        "\n",
        "for word in input_str:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlgyrTOH2lRG",
        "outputId": "16806e3f-b18e-4d8e-cfef-9fa44847c5bb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y\n",
            "o\n",
            "u\n",
            " \n",
            "h\n",
            "a\n",
            "v\n",
            "e\n",
            " \n",
            "6\n",
            " \n",
            "c\n",
            "h\n",
            "o\n",
            "c\n",
            "o\n",
            "l\n",
            "a\n",
            "t\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "4\n",
            " \n",
            "c\n",
            "a\n",
            "n\n",
            "d\n",
            "i\n",
            "e\n",
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_str\n",
        "\n",
        "for word in input_str.split():\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MoI4-Z63KfH",
        "outputId": "64e48404-7373-4780-f630-d22304e3719b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You\n",
            "have\n",
            "6\n",
            "chocolate\n",
            "and\n",
            "4\n",
            "candies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_sent = []\n",
        "for word in input_str.split():\n",
        "  if word.isdigit():\n",
        "    temp = q.number_to_words(word)\n",
        "    cleaned_sent.append(temp)\n",
        "  else:\n",
        "    cleaned_sent.append(word)\n",
        "\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn3iXGi53QFO",
        "outputId": "fa64d016-a889-4486-d20c-2541484d41d0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You\n",
            "have\n",
            "6\n",
            "chocolate\n",
            "and\n",
            "4\n",
            "candies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG5-i1KZ3k-G",
        "outputId": "e98b38bf-e83b-4284-87c2-dd9937bea6be"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You', 'have', 'six', 'chocolate', 'and', 'four', 'candies']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets remove punctuation !,?,.,etc\n",
        "\n",
        "import string\n",
        "string.punctuation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "heX3Rw7U3q8N",
        "outputId": "7622dd05-7e3f-4589-b05f-99dd06cf1dfe"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rem_punct(text):\n",
        "  #creating translation\n",
        "  translator = str.maketrans(\"\",\"\", string.punctuation)\n",
        "  return text.translate(translator)"
      ],
      "metadata": {
        "id": "MU6Kslp53_h2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rem_punct(\"Wow! The quick, brown fox, who'd jumped over the lazy dogs, ran fast, fast, fast!?!;\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-fkpnTOf4dpm",
        "outputId": "9e805a5f-a9ed-447f-c1ac-40c3ad6ce2e3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wow The quick brown fox whod jumped over the lazy dogs ran fast fast fast'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Wow! The quick, brown fox, who'd jumped over the lazy dogs, ran fast, fast, fast!?!;\"\n",
        "text.translate(\"Ram is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R4X91PgK4ut1",
        "outputId": "d44b8da5-3688-446a-c87d-8dd1edf7ba83"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Wow! The quick, brown fox, who'd jumped over the lazy dogs, ran fast, fast, fast!?!;\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"Hello Sam!\"\n",
        "mytable = txt.maketrans(\"S\", \"P\")\n",
        "print(mytable)\n",
        "print(txt.translate(mytable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs8Y19105Dwd",
        "outputId": "ef1b433f-0673-4a2a-8986-e8cb1f05f808"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{83: 80}\n",
            "Hello Pam!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = \"There is no need to panic. We need to work together, take small yet important strides towards success.\"\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "y-AhlEuy5kNe",
        "outputId": "9b5e86f8-78e3-46e4-f4ac-78d129793721"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There is no need to panic. We need to work together, take small yet important strides towards success.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.regexp import WhitespaceTokenizer\n",
        "tokens = WhitespaceTokenizer().tokenize(m)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGJ9Eo-565gW",
        "outputId": "c028b6e1-d02f-4494-9aaa-06ece9556af9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There',\n",
              " 'is',\n",
              " 'no',\n",
              " 'need',\n",
              " 'to',\n",
              " 'panic.',\n",
              " 'We',\n",
              " 'need',\n",
              " 'to',\n",
              " 'work',\n",
              " 'together,',\n",
              " 'take',\n",
              " 'small',\n",
              " 'yet',\n",
              " 'important',\n",
              " 'strides',\n",
              " 'towards',\n",
              " 'success.']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get unique no of tokens/words from this\n",
        "\n",
        "voc = set(tokens) #vocabulary is unique word in the sentence\n",
        "voc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glJxXral7JLl",
        "outputId": "51489f01-ecaa-48fc-d203-408d07ea2a85"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'There',\n",
              " 'We',\n",
              " 'important',\n",
              " 'is',\n",
              " 'need',\n",
              " 'no',\n",
              " 'panic.',\n",
              " 'small',\n",
              " 'strides',\n",
              " 'success.',\n",
              " 'take',\n",
              " 'to',\n",
              " 'together,',\n",
              " 'towards',\n",
              " 'work',\n",
              " 'yet'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming >> process of reducing words to its word stem (removing prefix and suffix) also called as lemma\n",
        "\n",
        "words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\"]\n"
      ],
      "metadata": {
        "id": "pMLRIxFC7O-M"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk .stem import PorterStemmer\n",
        "\n",
        "stemming = PorterStemmer()"
      ],
      "metadata": {
        "id": "AvI3XtC88SyG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"eating\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Jh4oYem18daN",
        "outputId": "3d1bd1ca-f77f-4cae-8c8f-206d6700824b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"------->\"+stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxUBV9SP8fnk",
        "outputId": "2d9567f0-0116-459d-b99c-883fc534f2cc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating------->eat\n",
            "eats------->eat\n",
            "eaten------->eaten\n",
            "writing------->write\n",
            "writes------->write\n",
            "programming------->program\n",
            "programs------->program\n",
            "history------->histori\n",
            "finally------->final\n",
            "finalized------->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"unhappy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "66o8pQJh8jzc",
        "outputId": "de5ba023-9f33-4ed6-9036-d1d1d9f2581e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unhappi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the above output is wrong\n",
        "\n",
        "#RegexpStemmer\n",
        "from nltk.stem import RegexpStemmer\n",
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "reg_stemmer.stem(\"eating\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DNH1FI5r9Ou1",
        "outputId": "b8408dbe-aa96-4202-a885-5e358c39816c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"ingeating\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YTMbFnx49ktT",
        "outputId": "71119f5c-5ed6-49f0-cdfa-685e7c573c75"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ingeat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#snowball stemmer (porter 2)\n",
        "from nltk.stem import SnowballStemmer\n",
        "snowballstemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "0V07OqH_9rSM"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+snowballstemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9eXadFb99v0",
        "outputId": "ed958192-2e0c-485f-e738-80c8bfa434f5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating----->eat\n",
            "eats----->eat\n",
            "eaten----->eaten\n",
            "writing----->write\n",
            "writes----->write\n",
            "programming----->program\n",
            "programs----->program\n",
            "history----->histori\n",
            "finally----->final\n",
            "finalized----->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "#lemma >> root word\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "2klglOmG-GUs"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty05bXhn-xsz",
        "outputId": "b7ba0875-7f63-425d-b734-db321ff82433"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"eating\", pos=\"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bL7R1Lp--3wU",
        "outputId": "9625a858-aea2-4176-89d8-33ef0a200cb6"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+lemmatizer.lemmatize(word, pos=\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20OOIzLt-97T",
        "outputId": "9ad7c29c-04b3-40e3-eec3-1f0fbb0c5398"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating----->eat\n",
            "eats----->eat\n",
            "eaten----->eat\n",
            "writing----->write\n",
            "writes----->write\n",
            "programming----->program\n",
            "programs----->program\n",
            "history----->history\n",
            "finally----->finally\n",
            "finalized----->finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "#multilingual wordnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh8ipYI1_SmM",
        "outputId": "3f790097-7623-4e36-e7af-763fb06deca3"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer.lemmatize(\"better\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m_tSTM5W_2Wb",
        "outputId": "914ed8be-9fd0-4701-f9a9-188c92230e55"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stopword >> I am going to delhi >> to\n",
        "#stop words are commonly used words that should be ignored in text analysis\n",
        "#is, the, and, a this, was, that, in\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB5jwzFNADfj",
        "outputId": "b2b30f03-0a6b-4d51-b351-edf58c67aa04"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is an example to demonstrate stop words removing. It is very useful to analysis and has to be done after tokenization \"\n",
        "\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "COciuUwvBGBT",
        "outputId": "9c739c40-6c57-4b9c-9bb6-5614f129b2ce"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is an example to demonstrate stop words removing. It is very useful to analysis and has to be done after tokenization '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "AeiwWyN_BTjt"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgCRkg8xBuK8",
        "outputId": "9e14dcf5-2606-4b79-8ccd-2142b9aa2e3b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'an',\n",
              " 'example',\n",
              " 'to',\n",
              " 'demonstrate',\n",
              " 'stop',\n",
              " 'words',\n",
              " 'removing',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'very',\n",
              " 'useful',\n",
              " 'to',\n",
              " 'analysis',\n",
              " 'and',\n",
              " 'has',\n",
              " 'to',\n",
              " 'be',\n",
              " 'done',\n",
              " 'after',\n",
              " 'tokenization']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words(\"english\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2uFbdKrBvED",
        "outputId": "6b660965-a591-42fa-c317-eb0664e6d46a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words(\"french\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWqSVUdKBzcT",
        "outputId": "cd99304a-aaa6-4496-c5d8-dd74a34fe0c3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['au',\n",
              " 'aux',\n",
              " 'avec',\n",
              " 'ce',\n",
              " 'ces',\n",
              " 'dans',\n",
              " 'de',\n",
              " 'des',\n",
              " 'du',\n",
              " 'elle',\n",
              " 'en',\n",
              " 'et',\n",
              " 'eux',\n",
              " 'il',\n",
              " 'ils',\n",
              " 'je',\n",
              " 'la',\n",
              " 'le',\n",
              " 'les',\n",
              " 'leur',\n",
              " 'lui',\n",
              " 'ma',\n",
              " 'mais',\n",
              " 'me',\n",
              " 'même',\n",
              " 'mes',\n",
              " 'moi',\n",
              " 'mon',\n",
              " 'ne',\n",
              " 'nos',\n",
              " 'notre',\n",
              " 'nous',\n",
              " 'on',\n",
              " 'ou',\n",
              " 'par',\n",
              " 'pas',\n",
              " 'pour',\n",
              " 'qu',\n",
              " 'que',\n",
              " 'qui',\n",
              " 'sa',\n",
              " 'se',\n",
              " 'ses',\n",
              " 'son',\n",
              " 'sur',\n",
              " 'ta',\n",
              " 'te',\n",
              " 'tes',\n",
              " 'toi',\n",
              " 'ton',\n",
              " 'tu',\n",
              " 'un',\n",
              " 'une',\n",
              " 'vos',\n",
              " 'votre',\n",
              " 'vous',\n",
              " 'c',\n",
              " 'd',\n",
              " 'j',\n",
              " 'l',\n",
              " 'à',\n",
              " 'm',\n",
              " 'n',\n",
              " 's',\n",
              " 't',\n",
              " 'y',\n",
              " 'été',\n",
              " 'étée',\n",
              " 'étées',\n",
              " 'étés',\n",
              " 'étant',\n",
              " 'étante',\n",
              " 'étants',\n",
              " 'étantes',\n",
              " 'suis',\n",
              " 'es',\n",
              " 'est',\n",
              " 'sommes',\n",
              " 'êtes',\n",
              " 'sont',\n",
              " 'serai',\n",
              " 'seras',\n",
              " 'sera',\n",
              " 'serons',\n",
              " 'serez',\n",
              " 'seront',\n",
              " 'serais',\n",
              " 'serait',\n",
              " 'serions',\n",
              " 'seriez',\n",
              " 'seraient',\n",
              " 'étais',\n",
              " 'était',\n",
              " 'étions',\n",
              " 'étiez',\n",
              " 'étaient',\n",
              " 'fus',\n",
              " 'fut',\n",
              " 'fûmes',\n",
              " 'fûtes',\n",
              " 'furent',\n",
              " 'sois',\n",
              " 'soit',\n",
              " 'soyons',\n",
              " 'soyez',\n",
              " 'soient',\n",
              " 'fusse',\n",
              " 'fusses',\n",
              " 'fût',\n",
              " 'fussions',\n",
              " 'fussiez',\n",
              " 'fussent',\n",
              " 'ayant',\n",
              " 'ayante',\n",
              " 'ayantes',\n",
              " 'ayants',\n",
              " 'eu',\n",
              " 'eue',\n",
              " 'eues',\n",
              " 'eus',\n",
              " 'ai',\n",
              " 'as',\n",
              " 'avons',\n",
              " 'avez',\n",
              " 'ont',\n",
              " 'aurai',\n",
              " 'auras',\n",
              " 'aura',\n",
              " 'aurons',\n",
              " 'aurez',\n",
              " 'auront',\n",
              " 'aurais',\n",
              " 'aurait',\n",
              " 'aurions',\n",
              " 'auriez',\n",
              " 'auraient',\n",
              " 'avais',\n",
              " 'avait',\n",
              " 'avions',\n",
              " 'aviez',\n",
              " 'avaient',\n",
              " 'eut',\n",
              " 'eûmes',\n",
              " 'eûtes',\n",
              " 'eurent',\n",
              " 'aie',\n",
              " 'aies',\n",
              " 'ait',\n",
              " 'ayons',\n",
              " 'ayez',\n",
              " 'aient',\n",
              " 'eusse',\n",
              " 'eusses',\n",
              " 'eût',\n",
              " 'eussions',\n",
              " 'eussiez',\n",
              " 'eussent']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "zGhc8AX8B1UK"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[word for word in words if word.lower() not in stop_words]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwxxF0WMCLAr",
        "outputId": "6dcf6cdf-8d27-44ba-bcc8-429a22eec090"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['example',\n",
              " 'demonstrate',\n",
              " 'stop',\n",
              " 'words',\n",
              " 'removing',\n",
              " '.',\n",
              " 'useful',\n",
              " 'analysis',\n",
              " 'done',\n",
              " 'tokenization']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parts of Speech  is the process of labelling each wordin the sentence with grammatical  role >> noun, pronoun, adjective\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng') #pos tagger\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhx3-E9xCVWL",
        "outputId": "60b1a1be-a1e6-4969-ac7b-af1f039b9014"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "pos_tag(words)\n",
        "\n",
        "#DT>> determiner\n",
        "#VBZ >> third form of verb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0RLJpsZC6ZS",
        "outputId": "92a43036-4a83-4035-8e9e-268bc03ee21a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('example', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('demonstrate', 'VB'),\n",
              " ('stop', 'JJ'),\n",
              " ('words', 'NNS'),\n",
              " ('removing', 'VBG'),\n",
              " ('.', '.'),\n",
              " ('It', 'PRP'),\n",
              " ('is', 'VBZ'),\n",
              " ('very', 'RB'),\n",
              " ('useful', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('analysis', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('has', 'VBZ'),\n",
              " ('to', 'TO'),\n",
              " ('be', 'VB'),\n",
              " ('done', 'VBN'),\n",
              " ('after', 'IN'),\n",
              " ('tokenization', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfSouNGiDBsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}